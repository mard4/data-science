{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connection import * \n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine \n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DB_HOST = DB_HOST\n",
    "DB_NAME = DB_NAME\n",
    "DB_USER = DB_USER       \n",
    "DB_PASS = DB_PASS       \n",
    "DB_PORT = DB_PORT              \n",
    "\n",
    "engine = create_engine(f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "def get_boolean_columns(engine, schema, table_name):\n",
    "    \"\"\"Get the right schema and table name for the boolean columns.\"\"\"\n",
    "    query = f\"\"\"\n",
    "            SELECT column_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = '{schema}' AND table_name = '{table_name}' AND data_type = 'boolean';\n",
    "            \"\"\"\n",
    "    result = pd.read_sql(query, engine)\n",
    "    return result['column_name'].tolist()\n",
    "\n",
    "clinical = pd.read_sql('SELECT * FROM project.clinical', engine)\n",
    "pain = pd.read_sql('SELECT * FROM project.pain', engine)\n",
    "patient = pd.read_sql('SELECT * FROM project.patient', engine)\n",
    "psychological = pd.read_sql('SELECT * FROM project.psychological', engine)\n",
    "radvice = pd.read_sql('SELECT * FROM project.radvice', engine)\n",
    "work = pd.read_sql('SELECT * FROM project.work', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bool_to_int(table, engine, table_name):   \n",
    "    \"\"\"Get Boolean columns from PostgreSQL and convert them to int64 to overcome with NANs\"\"\" \n",
    "    bool_cols = get_boolean_columns(engine, 'project', table_name)\n",
    "    for col in bool_cols:\n",
    "        table[col] = table[col].astype('Int64')\n",
    "    return table\n",
    "\n",
    "clinical = convert_bool_to_int(clinical, engine, 'clinical')\n",
    "pain = convert_bool_to_int(pain, engine, 'pain')\n",
    "patient = convert_bool_to_int(patient, engine, 'patient')\n",
    "psychological = convert_bool_to_int(psychological, engine, 'psychological')\n",
    "radvice = convert_bool_to_int(radvice, engine, 'radvice')\n",
    "work = convert_bool_to_int(work, engine, 'work')\n",
    "#patient.serious_disease.value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check final size of df:  1527\n",
      "Categorical features (Int64): ['treatment', 'family_history', 'serious_disease', 'fever', 'uses_analgesics', 'uses_corticosteroids', 'neurogenic_signals', 'loss_muscle_strength', 'failure_symptoms', 'depression', 'stress', 'sick_leave', 'earlier_hospitalization', 'paidwork']\n"
     ]
    }
   ],
   "source": [
    "# Join all the tables\n",
    "df_merged = radvice.merge(patient, left_on='patient_id', right_on='patient_id', how='left')\n",
    "df_merged = df_merged.merge(clinical, left_on='patient_id', right_on='patient_id', how='left')\n",
    "df_merged = df_merged.merge(psychological, left_on='patient_id', right_on='patient_id', how='left')\n",
    "df_merged = df_merged.merge(pain, left_on='patient_id', right_on='patient_id', how='left')\n",
    "df_merged = df_merged.merge(work, left_on='patient_id', right_on='patient_id', how='left')\n",
    "df_merged = df_merged.drop(columns=['patient_id','treatment_description'])\n",
    "print(\"Check final size of df: \", len(df_merged))\n",
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "# continous\n",
    "continous_columns =  [\n",
    "    'decreased_mobility',\n",
    "    'weightloss_per_year',\n",
    "    'extremely_nervous',\n",
    "    'irrational_thoughts_risk_lasting',\n",
    "    'coping_strategy',\n",
    "    'kinesiophobia_physical_exercise',\n",
    "    'kinesiophobia_pain_stop',\n",
    "    'nocturnal_pain',\n",
    "    'continuous_pain',\n",
    "    'duration_of_pain',\n",
    "    'neck_pain_intensity',\n",
    "    'low_back_pain_intensity',\n",
    "    'arm_left_pain_intensity',\n",
    "    'arm_right_pain_intensity',\n",
    "    'leg_left_pain_intensity',\n",
    "    'leg_right_pain_intensity'\n",
    "]\n",
    "df[continous_columns] = df[continous_columns].astype(float)\n",
    "\n",
    "cat_cols = [col for col in df.columns if str(df[col].dtype).lower().startswith('int')]\n",
    "print(\"Categorical features (Int64):\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1527, 30)\n",
      "Shape of y: (1527,)\n",
      "Shape of X: (1527, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Convert age to numerical\n",
    "df['age'] = df['age'].map({\n",
    "    '0-19': 10, '20-29': 25, '30-39': 35, '40-49': 45,\n",
    "    '50-59': 55, '60-69': 65, '70-79': 75, '>=80': 85\n",
    "}).astype(float)\n",
    "\n",
    "# Separate features (X) and target (y).\n",
    "X, y = df.drop(columns=['treatment']), df['treatment']\n",
    "column_names = X.columns\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "#print(\"Missing before:\", np.isnan(X).sum())\n",
    "\n",
    "# Custom transformer for feature engineering.\n",
    "class CustomFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_names):\n",
    "        self.column_names = column_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Convert array back to DataFrame so we can manipulate columns by name\n",
    "        df = pd.DataFrame(X, columns=self.column_names)\n",
    "        \n",
    "        # Arm, leg, neck\n",
    "        df['arm_pain'] = ((df['arm_left_pain_intensity'] > 0) | (df['arm_right_pain_intensity'] > 0)).astype('Int64')\n",
    "        df['leg_pain'] = ((df['leg_left_pain_intensity'] > 0) | (df['leg_right_pain_intensity'] > 0)).astype('Int64')\n",
    "        df['neck_pain'] = (df['neck_pain_intensity'] > 0).astype('Int64')\n",
    "\n",
    "        # Kinesiophobia\n",
    "        df['kinesiophobia'] = df[['kinesiophobia_pain_stop','kinesiophobia_physical_exercise']].mean(axis=1)\n",
    "\n",
    "        df = df.drop(columns=['kinesiophobia_pain_stop','kinesiophobia_physical_exercise',\n",
    "                              'arm_left_pain_intensity','arm_right_pain_intensity',\n",
    "                                'leg_left_pain_intensity','leg_right_pain_intensity',\n",
    "                                'neck_pain_intensity',\n",
    "                                ])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "fe = CustomFeatureEngineer(column_names=column_names)\n",
    "X_fe = fe.fit_transform(X)\n",
    "X_fe_df = pd.DataFrame(X_fe, columns=fe.transform(pd.DataFrame(X, columns=column_names)).columns)\n",
    "print(\"Shape of X:\", X_fe_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature indices for SMOTENC: ['treatment', 'family_history', 'serious_disease', 'fever', 'uses_analgesics', 'uses_corticosteroids', 'neurogenic_signals', 'loss_muscle_strength', 'failure_symptoms', 'depression', 'stress', 'sick_leave', 'earlier_hospitalization', 'paidwork']\n"
     ]
    }
   ],
   "source": [
    "#X_fe = pipeline.named_steps['feature_engineering'].transform(X_train)\n",
    "#cat_cols = [i for i, dt in enumerate(X_fe.dtypes) if dt.name == 'Int64']\n",
    "print(\"Categorical feature indices for SMOTENC:\", cat_cols)\n",
    "cat_cols_idx =[1, 2, 3, 4, 5, 6, 9, 10, 11, 13, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fe_df, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.61      0.56       131\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.48      0.57      0.52       128\n",
      "\n",
      "    accuracy                           0.50       306\n",
      "   macro avg       0.20      0.24      0.22       306\n",
      "weighted avg       0.42      0.50      0.46       306\n",
      "\n",
      "Mean CV accuracy:: 0.4656\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "over2 = SMOTENC(categorical_features=cat_cols_idx, sampling_strategy='all', random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=50, skip_complete=True)),\n",
    "    #('smote', over),  # activate for oversampling\n",
    "    ##('undersample', under),   # activate for undersampling\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced',n_estimators = 500, random_state = 42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(f\"Test score: {score:.4f}\")\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred,))\n",
    "\n",
    "\n",
    "# STRATIFIED cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "print(f\"Mean CV accuracy:: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on PCA features - Test score: 0.4673\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.59      0.53       131\n",
      "           2       0.50      0.06      0.11        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.45      0.50      0.48       128\n",
      "\n",
      "    accuracy                           0.47       306\n",
      "   macro avg       0.29      0.23      0.22       306\n",
      "weighted avg       0.45      0.47      0.44       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=50)),\n",
    "    #('smote', over),  # activate for oversampling\n",
    "    ##('undersample', under),   # activate for undersampling\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=10)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        n_estimators=500,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"Random Forest on PCA features - Test score: {test_score:.4f}\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest on PCA features - Test score: 0.4641\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline up to PCA\n",
    "pipeline_pca = ImbPipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=50)),\n",
    "    #('smote', over),  # activate for oversampling\n",
    "    ##('undersample', under),   # activate for undersampling\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=4))\n",
    "])\n",
    "\n",
    "X_train_pca = pipeline_pca.fit_transform(X_train, y_train)\n",
    "X_test_pca = pipeline_pca.transform(X_test)\n",
    "\n",
    "# Train classifier separately\n",
    "clf_pca = RandomForestClassifier(class_weight='balanced', n_estimators=500, random_state=42)\n",
    "clf_pca.fit(X_train_pca, y_train)\n",
    "test_score = clf_pca.score(X_test_pca, y_test)\n",
    "print(f\"Random Forest on PCA features - Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with Univariate Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score with SelectKBest: 0.3790849673202614\n",
      "Mean CV score with SelectKBest: 0.37524483017250615\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection with Univariate Statistical Tests\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "pipeline_kbest = ImbPipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=50, skip_complete=True)),\n",
    "    #('smote', over),  # activate for oversampling\n",
    "    ##('undersample', under),   # activate for undersampling\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('select', SelectKBest(score_func=f_classif, k=10)),  # <-- Select top 10 features\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced',n_estimators = 500, random_state = 42))\n",
    "])\n",
    "pipeline_kbest.fit(X_train, y_train)\n",
    "score_kbest = pipeline_kbest.score(X_test, y_test)\n",
    "print(\"Test score with SelectKBest:\", score_kbest)\n",
    "\n",
    "cv_scores_kbest = cross_val_score(pipeline_kbest, X, y, cv=5)\n",
    "print(\"Mean CV score with SelectKBest:\", cv_scores_kbest.mean())\n",
    "selector = pipeline_kbest.named_steps['select']\n",
    "selected_mask = selector.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['age', 'serious_disease', 'fever', 'uses_corticosteroids', 'coping_strategy', 'nocturnal_pain', 'continuous_pain', 'duration_of_pain', 'paidwork', 'leg_pain']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Run feature engineering manually\n",
    "fe = pipeline_kbest.named_steps['feature_engineering']\n",
    "X_fe = fe.transform(X_train)  # shape: (n_samples, n_features_after_FE)\n",
    "\n",
    "# Step 2: Build final feature names list that matches the output exactly\n",
    "base_names = list(fe.column_names)\n",
    "\n",
    "# Drop columns that are removed in transform()\n",
    "to_drop = [\n",
    "    'kinesiophobia_pain_stop',\n",
    "    'kinesiophobia_physical_exercise',\n",
    "    'arm_left_pain_intensity',\n",
    "    'arm_right_pain_intensity',\n",
    "    'leg_left_pain_intensity',\n",
    "    'leg_right_pain_intensity',\n",
    "    'neck_pain_intensity',\n",
    "]\n",
    "final_names = [name for name in base_names if name not in to_drop]\n",
    "\n",
    "# Add engineered features (in the exact order from your transformer!)\n",
    "final_names += ['arm_pain', 'leg_pain', 'neck_pain', 'kinesiophobia']\n",
    "\n",
    "# You also converted 'age' to a numeric, but did not drop it by name\n",
    "# So it stays as 'age'\n",
    "# (Double-check that your transformer doesn't rename or drop it)\n",
    "\n",
    "# Step 3: Ensure the names match the actual shape\n",
    "assert len(final_names) == X_fe.shape[1], f\"Name count ({len(final_names)}) != features ({X_fe.shape[1]})\"\n",
    "\n",
    "# Step 4: Apply SelectKBest mask\n",
    "selector = pipeline_kbest.named_steps['select']\n",
    "mask = selector.get_support()\n",
    "\n",
    "selected_feature_names = np.array(final_names)[mask]\n",
    "print(\"Selected features:\", selected_feature_names.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.49673202614379086\n"
     ]
    }
   ],
   "source": [
    "### re-run the pipeline with selected features\n",
    "\n",
    "pipeline_kbest = ImbPipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=50, skip_complete=True)),\n",
    "    #('smote', over),  # activate for oversampling\n",
    "    ##('undersample', under),   # activate for undersampling\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('select', SelectKBest(score_func=f_classif, k=20)),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced',n_estimators = 500, random_state = 42))\n",
    "])\n",
    "\n",
    "pipeline_kbest.fit(X_train, y_train)\n",
    "score = pipeline_kbest.score(X_test, y_test)\n",
    "print(\"Test score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
